@article {Vosoughi1146,
	author = {Vosoughi, Soroush and Roy, Deb and Aral, Sinan},
	title = {The spread of true and false news online},
	volume = {359},
	number = {6380},
	pages = {1146--1151},
	year = {2018},
	doi = {10.1126/science.aap9559},
	publisher = {American Association for the Advancement of Science},
	abstract = {There is worldwide concern over false news and the possibility that it can influence political, economic, and social well-being. To understand how false news spreads, Vosoughi et al. used a data set of rumor cascades on Twitter from 2006 to 2017. About 126,000 rumors were spread by \~{}3 million people. False news reached more people than the truth; the top 1\% of false news cascades diffused to between 1000 and 100,000 people, whereas the truth rarely diffused to more than 1000 people. Falsehood also diffused faster than the truth. The degree of novelty and the emotional reactions of recipients may be responsible for the differences observed.Science, this issue p. 1146We investigated the differential diffusion of all of the verified true and false news stories distributed on Twitter from 2006 to 2017. The data comprise ~126,000 stories tweeted by ~3 million people more than 4.5 million times. We classified news as true or false using information from six independent fact-checking organizations that exhibited 95 to 98\% agreement on the classifications. Falsehood diffused significantly farther, faster, deeper, and more broadly than the truth in all categories of information, and the effects were more pronounced for false political news than for false news about terrorism, natural disasters, science, urban legends, or financial information. We found that false news was more novel than true news, which suggests that people were more likely to share novel information. Whereas false stories inspired fear, disgust, and surprise in replies, true stories inspired anticipation, sadness, joy, and trust. Contrary to conventional wisdom, robots accelerated the spread of true and false news at the same rate, implying that false news spreads more than the truth because humans, not robots, are more likely to spread it.},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/359/6380/1146},
	eprint = {http://science.sciencemag.org/content/359/6380/1146.full.pdf},
	journal = {Science}
}

@article {Lazer1094,
	author = {Lazer, David M. J. and Baum, Matthew A. and Benkler, Yochai and Berinsky, Adam J. and Greenhill, Kelly M. and Menczer, Filippo and Metzger, Miriam J. and Nyhan, Brendan and Pennycook, Gordon and Rothschild, David and Schudson, Michael and Sloman, Steven A. and Sunstein, Cass R. and Thorson, Emily A. and Watts, Duncan J. and Zittrain, Jonathan L.},
	title = {The science of fake news},
	volume = {359},
	number = {6380},
	pages = {1094--1096},
	year = {2018},
	doi = {10.1126/science.aao2998},
	publisher = {American Association for the Advancement of Science},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/359/6380/1094},
	eprint = {http://science.sciencemag.org/content/359/6380/1094.full.pdf},
	journal = {Science}
}


@article{Ishikawa2013,
author = {Ishikawa, Yoshiharu and Li, Jianzhong and Wang, Wei and Zhang, Rui and Zhang, Wenjie},
file = {::},
title = {{Web Technologies and Applications}},
year = {2013}
}
@inproceedings{Lee2010,
abstract = {Web-based social systems enable new community-based opportu- nities for participants to engage, share, and interact. This com- munity value and related services like search and advertising are threatened by spammers, content polluters, and malware dissemi- nators. In an effort to preserve community value and ensure long- term success, we propose and evaluate a honeypot-based approach for uncovering social spammers in online social systems. Two of the key components of the proposed approach are: (1) The deploy- ment of social honeypots for harvesting deceptive spam profiles from social networking communities; and (2) Statistical analysis of the properties of these spam profiles for creating spam classifiers to actively filter out existing and new spammers. We describe the conceptual framework and design considerations of the proposed approach, and we present concrete observations from the deploy- ment of social honeypots in MySpace and Twitter. We find that the deployed social honeypots identify social spammers with low false positive rates and that the harvested spam data contains signals that are strongly correlated with observable profile features (e.g., content, friend information, posting patterns, etc.). Based on these profile features, we develop machine learning based classifiers for identifying previously unknown spammers with high precision and a low rate of false positives. Categories},
author = {Lee, Kyumin and Caverlee, James and Webb, Steve},
booktitle = {Proceeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval - SIGIR '10},
doi = {10.1145/1835449.1835522},
file = {::},
isbn = {9781450301534},
title = {{Uncovering social spammers}},
year = {2010}
}
@inproceedings{Hu2013,
abstract = {Abstract The availability of microblogging , like Twitter and Sina Weibo, makes it a popular platform for spammers to unfairly overpower normal users with unwanted content via social networks, known as social spamming . The rise of social spamming can significantly hinder ...},
author = {Hu, Xia and Tang, Jiliang and Zhang, Yanchao and Liu, Huan},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
file = {::},
isbn = {9781577356332},
issn = {10450823},
title = {{Social spammer detection in microblogging}},
year = {2013}
}
@inproceedings{Kwon2013,
abstract = {â€”The problem of identifying rumors is of practical importance especially in online social networks, since infor- mation can diffuse more rapidly and widely than the offline counterpart. In this paper, we identify characteristics of rumors by examining the following three aspects of diffusion: temporal, structural, and linguistic. For the temporal characteristics, we propose a new periodic time series model that considers daily and external shock cycles, where the model demonstrates that rumor likely have fluctuations over time. We also identify key structural and linguistic differences in the spread of rumors and non-rumors. Our selected features classify rumors with high precision and recall in the range of 87{\%} to 92{\%}, that is higher},
author = {Kwon, Sejeong and Cha, Meeyoung and Jung, Kyomin and Chen, Wei and Wang, Yajun},
booktitle = {Proceedings - IEEE International Conference on Data Mining, ICDM},
doi = {10.1109/ICDM.2013.61},
file = {::},
isbn = {978-0-7695-5108-1},
issn = {15504786},
keywords = {Diffusion Network,Rumor,Sentiment Analysis,Social Media,Time Series},
title = {{Prominent features of rumor propagation in online social media}},
year = {2013}
}
@inproceedings{Wu2015,
abstract = {This paper studies the problem of automatic detection of false rumors on Sina Weibo, the popular Chinese microblogging social network. Traditional feature-based approaches extract features from the false rumor message, its author, as well as the statistics of its responses to form a flat feature vector. This ignores the propagation structure of the messages and has not achieved very good results. We propose a graph-kernel based hybrid SVM classifier which captures the high-order propagation patterns in addition to semantic features such as topics and sentiments. The new model achieves a classification accuracy of 91.3{\%} on randomly selected Weibo dataset, significantly higher than state-of-the-art approaches. Moreover, our approach can be applied at the early stage of rumor propagation and is 88{\%} confident in detecting an average false rumor just 24 hours after the initial broadcast.},
author = {Wu, Ke and Yang, Song and Zhu, Kenny Q.},
booktitle = {Proceedings - International Conference on Data Engineering},
doi = {10.1109/ICDE.2015.7113322},
file = {::},
isbn = {9781479979639},
issn = {10844627},
title = {{False rumors detection on Sina Weibo by propagation structures}},
year = {2015}
}
@inproceedings{Yang2012,
abstract = {The problem of gauging information credibility on social networks has received considerable attention in recent years. Most previous work has chosen Twitter, the world's largest micro-blogging platform, as the premise of research. In this work, we shift the premise and study the problem of information credibility on Sina Weibo, China's leading micro-blogging service provider. With eight times more users than Twitter, Sina Weibo is more of a Facebook-Twitter hybrid than a pure Twitter clone, and exhibits several important characteristics that distinguish it from Twitter. We collect an extensive set of microblogs which have been confirmed to be false rumors based on information from the official rumor-busting service provided by Sina Weibo. Unlike previous studies on Twitter where the labeling of rumors is done manually by the participants of the experiments, the official nature of this service ensures the high quality of the dataset. We then examine an extensive set of features that can be extracted from the microblogs, and train a classifier to automatically detect the rumors from a mixed set of true information and false information. The experiments show that some of the new features we propose are indeed effective in the classification, and even the features considered in previous studies have different implications with Sina Weibo than with Twitter. To the best of our knowledge, this is the first study on rumor analysis and detection on Sina Weibo.},
archivePrefix = {arXiv},
arxivId = {10.1145/2350190.2350203},
author = {Yang, Fan and Liu, Yang and Yu, Xiaohui and Yang, Min},
booktitle = {Proceedings of the ACM SIGKDD Workshop on Mining Data Semantics - MDS '12},
doi = {10.1145/2350190.2350203},
eprint = {2350190.2350203},
file = {::},
isbn = {9781450315463},
primaryClass = {10.1145},
title = {{Automatic detection of rumor on Sina Weibo}},
year = {2012}
}
@inproceedings{Liu2015,
abstract = {In this paper, we propose the first real time rumor debunk- ing algorithm for Twitter. We use cues from â€˜wisdom of the crowds', that is, the aggregate â€˜common sense' and in- vestigative journalism of Twitter users. We concentrate on identification of a rumor as an event that may comprise of one or more conflicting microblogs. We continue monitoring the rumor event and generate real time updates dynamically based on any additional information received. We show us- ing real streaming data that it is possible, using our ap- proach, to debunk rumors accurately and efficiently, often much},
archivePrefix = {arXiv},
arxivId = {arXiv:1601.00306v1},
author = {Liu, Xiaomo and Nourbakhsh, Armineh and Li, Quanzhi and Fang, Rui and Shah, Sameena},
booktitle = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management - CIKM '15},
doi = {10.1145/2806416.2806651},
eprint = {arXiv:1601.00306v1},
file = {::},
isbn = {9781450337946},
issn = {15504786},
title = {{Real-time Rumor Debunking on Twitter}},
year = {2015}
}
@inproceedings{Ma2015,
abstract = {ABSTRACT Automatically identifying rumors from online social media especially microblogging websites is an important research issue. Most of existing work for rumor detection focuses on modeling features related to microblog contents, users and propagation patterns, but ignore the importance of the variation of these social context features during the message propagation over time. In this study, we propose a novel approach to capture the temporal characteristics of these features based on the time series of rumoréˆ¥æªš lifecycle, for which time series modeling technique is applied to incorporate various social context information. Our experiments using the events in two microblog datasets confirm that the method outperforms state-of-the-art rumor detection approaches by large margins. Moreover, our model demonstrates strong performance on detecting rumors at early stage after their initial broadcast.},
author = {Ma, Jing and Gao, Wei and Wei, Zhongyu and Lu, Yueming and Wong, Kam-Fai},
booktitle = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management - CIKM '15},
doi = {10.1145/2806416.2806607},
file = {::},
isbn = {9781450337946},
title = {{Detect Rumors Using Time Series of Social Context Information on Microblogging Websites}},
year = {2015}
}
@article{Flanagin,
abstract = {People increasingly rely on Internet and web-based information despite evidence that it is potentially inaccurate and biased. Therefore, this study sought to assess people's perceptions of the credibility of various categories of Internet information compared to similar information provided by other media. The 1,041 respondents also were asked about whether they verified Internet information. Overall, respondents re-ported they considered Internet information to be as credible as that obtained from television, radio, and magazines, but not as credible as newspaper information. Credibility among the types of information sought, such as news and entertainment, varied across media channels. Respondents said they rarely verified web-based information, although this too varied by the type of information sought. Levels of experienceand how respondents perceived the credibility of information were related to whether they verified information. This study explores the social relevance of the findings and discusses them in terms of theoretical knowledge of advanced communication technologies. The Internet has quickly become a viable technology used by an estimated 130 million people' in 171 countries2 for a variety of communica-tion and information-sharing tasks. Internet technologies have been applied to education; have stimulated electronic commerce,4 have been used to develop online communities and cultures,5 and have helped organizations develop communication via intranets6 However, although information obtained via the Internet is abundant, easily available, and often comprehensive, it can differ from information obtained via other media sources in several respects. For instance, web-based information typically undergoes an editorial process prior to "publication" that may differ greatly from that of other media content. In addition, people are still experimenting with strategies to make sense of web-based informa-tion. Among the potential results of this relatively unchecked information flow and individuals' nascent sensemaking strategies is the possibility that information is intentionally or unintentionally inaccurate, biased, or mis-leading. Indeed, the growth of the Internet has seen an attendant growth of online fraud and mi{\~{}}information.{\~{}} Misinformation, of course, is not new with the Internet. However, many of the existing institutional, structural, and cognitive methods people employ to discern the relative value or accuracy of information (e.g., estab-Andrew I. Flanagin and Miriam I. Metzger are both assistant professors in the},
author = {Flanagin, Andrew 1 and Metzger, Miriam J},
file = {:home/kandy/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Flanagin, Metzger - Unknown - PERCEPTIONS OF INTERNET INFOMTION CREDIBILITY.pdf:pdf},
title = {{PERCEPTIONS OF INTERNET INFOMTION CREDIBILITY}}
}
@inproceedings{Castillo2011,
abstract = {We analyze the information credibility of news propagated through Twitter, a popular microblogging service. Previous research has shown that most of the messages posted on Twitter are truthful, but the service is also used to spread misinformation and false rumors, often unintentionally. On this paper we focus on automatic methods for assessing the credibility of a given set of tweets. Specifically, we analyze microblog postings related to "trending" topics, and classify them as credible or not credible, based on features extracted from them. We use features from users' posting and re-posting ("re-tweeting") behavior, from the text of the posts, and from citations to external sources. We evaluate our methods using a significant number of human assessments about the credibility of items on a recent sample of Twitter postings. Our results shows that there are measurable differences in the way messages propagate, that can be used to classify them automatically as credible or not credible, with precision and recall in the range of 70{\%} to 80{\%}.},
author = {Castillo, Carlos and Mendoza, Marcelo and Poblete, Barbara},
booktitle = {Proceedings of the 20th international conference on World wide web - WWW '11},
doi = {10.1145/1963405.1963500},
file = {:home/kandy/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Castillo, Mendoza, Poblete - 2011 - Information credibility on twitter.pdf:pdf},
isbn = {9781450306324},
title = {{Information credibility on twitter}},
year = {2011}
}
@misc{Wales2005,
abstract = {The journal Nature preformed a comparative analysis of scientific data entry accuracy between Wikipedia, a free online encyclopedia that anyone can edit, and Encyclopedia Britannica. The average science entry in Wikipedia contains around 4 inaccuracies; Britannica, about 3.},
author = {Wales, Jimmy},
booktitle = {Nature},
doi = {10.1038/438900a},
file = {::},
isbn = {0028-0836},
issn = {14764687},
pmid = {16355180},
title = {{Internet encyclopaedias go head to head}},
year = {2005}
}
@article{DeDeo2013,
abstract = {We investigate the computational structure of a paradigmatic example of distributed social interaction: that of the open-source Wikipedia community. We examine the statistical properties of its cooperative behavior, and perform model selection to determine whether this aspect of the system can be described by a finite-state process, or whether reference to an effectively unbounded resource allows for a more parsimonious description. We find strong evidence, in a majority of the most-edited pages, in favor of a collective-state model, where the probability of a "revert" action declines as the square root of the number of non-revert actions seen since the last revert. We provide evidence that the emergence of this social counter is driven by collective interaction effects, rather than properties of individual users.},
archivePrefix = {arXiv},
arxivId = {1212.0018},
author = {DeDeo, Simon},
doi = {10.1371/journal.pone.0075818},
eprint = {1212.0018},
file = {::},
isbn = {0027-8424},
issn = {19326203},
journal = {PLoS ONE},
pmid = {24130745},
title = {{Collective Phenomena and Non-Finite State Computation in a Human Social System}},
year = {2013}
}
@inproceedings{Priedhorsky2007,
abstract = {Wikipedia's brilliance and curse is that any user can edit any of the encyclopedia entries. We introduce the notion of the impact of an edit, measured by the number of times the edited version is viewed. Using several datasets, including recent logs of all article views, we show that an overwhelm- ing majority of the viewed words were written by frequent editors and that this majority is increasing. Similarly, using the same impact measure, we show that the probability of a typical article view being damaged is small but increasing, and we present empirically grounded classes of damage. Fi- nally, we make policy recommendations for Wikipedia and other wikis in light of these findings},
author = {Priedhorsky, Reid and Chen, Jilin and Lam, Shyong (Tony) K. and Panciera, Katherine and Terveen, Loren and Riedl, John},
booktitle = {Proceedings of the 2007 international ACM conference on Conference on supporting group work  - GROUP '07},
doi = {10.1145/1316624.1316663},
file = {::},
isbn = {9781595938459},
issn = {1595938451},
title = {{Creating, destroying, and restoring value in wikipedia}},
year = {2007}
}
@article{Collobert2011,
abstract = {We propose a unified neural network architecture and learning algorithm that can be applied to var-ious natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational re-quirements.},
author = {Collobert, Ronan and Weston, Jason and Bottou, L{\'{e}}on and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
file = {::},
journal = {Journal of Machine Learning Research},
keywords = {natural language processing,neural networks},
pages = {2493--2537},
title = {{Natural Language Processing (Almost) from Scratch}},
volume = {12},
year = {2011}
}
@article{Lazer2017,
annote = {Psychology of fake news},
author = {Lazer, David and Baum, Matthew and Grinberg, Nir and Friedland, Lisa and Joseph, Kenneth and Hobbs, Will and Mattsson, Carolina and {Benkler Harvard}, Yochai and Watts, Duncan},
file = {::},
title = {{Combating Fake News: An Agenda for Research and Action Drawn from presentations by}},
year = {2017}
}
@article{Hochreiter1997,
abstract = { Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms. },
author = {Hochreiter, Sepp and Schmidhuber, J{\"{u}}rgen},
doi = {10.1162/neco.1997.9.8.1735},
journal = {Neural Computation},
number = {8},
pages = {1735--1780},
title = {{Long Short-Term Memory}},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
volume = {9},
year = {1997}
}
@article{Goldberg2016,
abstract = {Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in fields such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.},
author = {Goldberg, Yoav},
file = {::},
journal = {Journal of Artificial Intelligence Research},
pages = {345--420},
title = {{A Primer on Neural Network Models for Natural Language Processing}},
volume = {57},
year = {2016}
}
@article{Goldsborough2016,
abstract = {Deep learning is a branch of artificial intelligence employing deep neural network architectures that has significantly advanced the state-of-the-art in computer vision, speech recognition, natural language processing and other domains. In November 2015, Google released {\$}\backslashtextit{\{}TensorFlow{\}}{\$}, an open source deep learning software library for defining, training and deploying machine learning models. In this paper, we review TensorFlow and put it in context of modern deep learning concepts and software. We discuss its basic computational paradigms and distributed execution model, its programming interface as well as accompanying visualization toolkits. We then compare TensorFlow to alternative libraries such as Theano, Torch or Caffe on a qualitative as well as quantitative basis and finally comment on observed use-cases of TensorFlow in academia and industry.},
archivePrefix = {arXiv},
arxivId = {1610.01178},
author = {Goldsborough, Peter},
doi = {10.1017/CBO9781107415324.004},
eprint = {1610.01178},
file = {::},
isbn = {9788578110796},
issn = {1098-6596},
pmid = {25246403},
title = {{A Tour of TensorFlow}},
year = {2016}
}
@article{Lipton2015,
abstract = {Countless learning tasks require dealing with sequential data. Image captioning, speech synthesis, and music generation all require that a model produce outputs that are sequences. In other domains, such as time series prediction, video analysis, and musical information retrieval, a model must learn from inputs that are sequences. Interactive tasks, such as translat-ing natural language, engaging in dialogue, and controlling a robot, often demand both capabilities. Recurrent neural networks (RNNs) are connec-tionist models that capture the dynamics of sequences via cycles in the network of nodes. Unlike standard feedforward neural networks, recurrent networks retain a state that can represent information from an arbitrarily long context window. Although recurrent neural networks have tradition-ally been difficult to train, and often contain millions of parameters, recent advances in network architectures, optimization techniques, and paral-lel computation have enabled successful large-scale learning with them. In recent years, systems based on long short-term memory (LSTM) and bidirectional (BRNN) architectures have demonstrated ground-breaking performance on tasks as varied as image captioning, language translation, and handwriting recognition. In this survey, we review and synthesize the research that over the past three decades first yielded and then made practical these powerful learning models. When appropriate, we reconcile conflicting notation and nomenclature. Our goal is to provide a self-contained explication of the state of the art together with a historical perspective and references to primary research.},
author = {Lipton, Zachary C and Berkowitz, John and Elkan, Charles},
file = {::},
title = {{A Critical Review of Recurrent Neural Networks for Sequence Learning}},
year = {2015}
}
@article{Ciampaglia2015,
abstract = {Traditional fact checking by expert journalists cannot keep up with the enormous volume of information that is now generated online. Computational fact checking may significantly enhance our ability to evaluate the veracity of dubious information. Here we show that the complexities of human fact checking can be approximated quite well by finding the shortest path between concept nodes under properly defined semantic proximity metrics on knowledge graphs. Framed as a network problem this approach is feasible with efficient computational techniques. We evaluate this approach by examining tens of thousands of claims related to history, entertainment, geography, and biographical information using a public knowledge graph extracted from Wikipedia. Statements independently known to be true consistently receive higher support via our method than do false ones. These findings represent a significant step toward scalable computational fact-checking methods that may one day mitigate the spread of harmful misinformation.},
archivePrefix = {arXiv},
arxivId = {1501.03471v1},
author = {Ciampaglia, Giovanni Luca and Shiralkar, Prashant and Rocha, Luis M. and Bollen, Johan and Menczer, Filippo and Flammini, Alessandro},
doi = {10.1371/journal.pone.0128193},
eprint = {1501.03471v1},
file = {::},
isbn = {19326203 (Electronic)},
issn = {19326203},
journal = {PLoS ONE},
pmid = {26083336},
title = {{Computational fact checking from knowledge networks}},
year = {2015}
}
@article{Ma,
abstract = {Microblogging platforms are an ideal place for spreading rumors and automatically debunking ru-mors is a crucial problem. To detect rumors, ex-isting approaches have relied on hand-crafted fea-tures for employing machine learning algorithms that require daunting manual effort. Upon facing a dubious claim, people dispute its truthfulness by posting various cues over time, which generates long-distance dependencies of evidence. This pa-per presents a novel method that learns continuous representations of microblog events for identifying rumors. The proposed model is based on recur-rent neural networks (RNN) for learning the hidden representations that capture the variation of contex-tual information of relevant posts over time. Ex-perimental results on datasets from two real-world microblog platforms demonstrate that (1) the RNN method outperforms state-of-the-art rumor detec-tion models that use hand-crafted features; (2) per-formance of the RNN-based algorithm is further improved via sophisticated recurrent units and ex-tra hidden layers; (3) RNN-based method detects rumors more quickly and accurately than existing techniques, including the leading online rumor de-bunking services.},
author = {Ma, Jing and Gao, Wei and Mitra, Prasenjit and Kwon, Sejeong and Jansen, Bernard J and Wong, Kam-Fai and Cha, Meeyoung},
file = {::},
title = {{Detecting Rumors from Microblogs with Recurrent Neural Networks}}
}
@inproceedings{Tacchini2017,
abstract = {In recent years, the reliability of information on the Internet has emerged as a crucial issue of modern society. Social network sites (SNSs) have revolutionized the way in which information is spread by allowing users to freely share content. As a consequence, SNSs are also increasingly used as vectors for the diffusion of misinformation and hoaxes. The amount of disseminated information and the rapidity of its diffusion make it practically impossible to assess reliability in a timely manner, highlighting the need for automatic hoax detection systems. As a contribution towards this objective, we show that Facebook posts can be classified with high accuracy as hoaxes or non-hoaxes on the basis of the users who "liked" them. We present two classification techniques, one based on logistic regression, the other on a novel adaptation of boolean crowdsourcing algorithms. On a dataset consisting of 15,500 Facebook posts and 909,236 users, we obtain classification accuracies exceeding 99{\%} even when the training set contains less than 1{\%} of the posts. We further show that our techniques are robust: they work even when we restrict our attention to the users who like both hoax and non-hoax posts. These results suggest that mapping the diffusion pattern of information can be a useful component of automatic hoax detection systems.},
archivePrefix = {arXiv},
arxivId = {1704.07506},
author = {Tacchini, Eugenio and Ballarin, Gabriele and {Della Vedova}, Marco L. and Moret, Stefano and de Alfaro, Luca},
booktitle = {CEUR Workshop Proceedings},
doi = {10.1257/jep.31.2.211},
eprint = {1704.07506},
file = {::},
issn = {16130073},
title = {{Some like it Hoax: Automated fake news detection in social networks}},
year = {2017}
}
@inproceedings{Wu2018,
abstract = {When a message, such as a piece of news, spreads in social networks, how can we classify it into categories of interests, such as genuine or fake news? Classiication of social media content is a fundamental task for social media mining, and most existing methods regard it as a text categorization problem and mainly focus on using content features, such as words and hashtags. However, for many emerging applications like fake news and rumor detection, it is very challenging, if not impossible, to identify useful features from content. For example, intentional spreaders of fake news may manipulate the content to make it look like real news. To address this problem, this paper concentrates on modeling the propagation of messages in a social network. Speciically, we propose a novel approach, TraceMiner, to (1) infer embeddings of social media users with social network structures; and (2) utilize an LSTM-RNN to represent and classify propagation pathways of a message. Since content information is sparse and noisy on social media, adopting TraceMiner allows to provide a high degree of classiication accuracy even in the absence of content information. Experimental results on real-world datasets show the superiority over state-of-the-art approaches on the task of fake news detection and news categorization.},
author = {Wu, Liang and Liu, Huan},
booktitle = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining  - WSDM '18},
doi = {10.1145/3159652.3159677},
isbn = {9781450355810},
title = {{Tracing Fake-News Footprints}},
year = {2018}
}

@inproceedings{Zhao2015,
 author = {Zhao, Zhe and Resnick, Paul and Mei, Qiaozhu},
 title = {Enquiring Minds: Early Detection of Rumors in Social Media from Enquiry Posts},
 booktitle = {Proceedings of the 24th International Conference on World Wide Web},
 series = {WWW '15},
 year = {2015},
 isbn = {978-1-4503-3469-3},
 location = {Florence, Italy},
 pages = {1395--1405},
 numpages = {11},
 url = {https://doi.org/10.1145/2736277.2741637},
 doi = {10.1145/2736277.2741637},
 acmid = {2741637},
 publisher = {International World Wide Web Conferences Steering Committee},
 address = {Republic and Canton of Geneva, Switzerland},
 keywords = {enquiry tweets, rumor detection, social media},
} 


@book {Goodfellow2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={www.deeplearningbook.org},
    year={2016}
}

@misc {WikipediaEN_RNN_unfold,
    author = {Francois Deloche},
    title = {Recurrent Neural Network unfold},
    year = {2013},
    note = {[Online; accessed April 27, 2013; \url{https://commons.wikimedia.org/wiki/File:Recurrent_neural_network_unfold.svg}; CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0)}
}
note = {Available at \url{http://www.qqq.com}, version 1.6.0}
@misc {WikipediaEN_FeedForward_Network,
    author = {Wikipedia Commons},
    title = {Feed Forward Network},
    year = {2006},
    note = {\url{https://en.wikipedia.org/wiki/File:Feed_forward_neural_net.gif}; CC BY-SA 3.0 (https://creativecommons.org/licenses/by-sa/3.0)}
}


@incollection{Bottou2012,
abstract = {Chapter 1 strongly advocates the stochastic back-propagation method to train neural networks. This is in fact an instance of a more general technique called stochastic gradient descent (SGD). This chapter provides background material, explains why SGD is a good learning algorithm when the training set is large, and provides useful recommendations.},
address = {Berlin, Heidelberg},
author = {Bottou, L{\'{e}}on},
booktitle = {Neural Networks: Tricks of the Trade: Second Edition},
doi = {10.1007/978-3-642-35289-8_25},
editor = {{Montavon Gr{\'{e}}goire
and Orr}, Genevi{\`{e}}ve B.
and M{\"{u}}ller Klaus-Robert},
isbn = {978-3-642-35289-8},
pages = {421--436},
publisher = {Springer Berlin Heidelberg},
title = {{Stochastic Gradient Descent Tricks}},
url = {https://doi.org/10.1007/978-3-642-35289-8{\_}25},
year = {2012}
}
@incollection{LeCunYannA.andBottou2012,
abstract = {The convergence of back-propagation learning is analyzed so as to explain common phenomenon observed by practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposed in serious technical publications. This paper gives some of those tricks, and offers explanations of why they work.},
address = {Berlin, Heidelberg},
author = {{LeCun Yann A.
and Bottou}, L{\'{e}}on
and Orr Genevieve B.
and M{\"{u}}ller Klaus-Robert},
booktitle = {Neural Networks: Tricks of the Trade: Second Edition},
doi = {10.1007/978-3-642-35289-8_3},
editor = {{Montavon Gr{\'{e}}goire
and Orr}, Genevi{\`{e}}ve B.
and M{\"{u}}ller Klaus-Robert},
isbn = {978-3-642-35289-8},
pages = {9--48},
publisher = {Springer Berlin Heidelberg},
title = {{Efficient BackProp}},
url = {https://doi.org/10.1007/978-3-642-35289-8{\_}3},
year = {2012}
}

@article{Pollack1990,
author = {Pollack, Jordan B},
doi = {https://doi.org/10.1016/0004-3702(90)90005-K},
issn = {0004-3702},
journal = {Artificial Intelligence},
number = {1},
pages = {77 -- 105},
title = {{Recursive distributed representations}},
url = {http://www.sciencedirect.com/science/article/pii/000437029090005K},
volume = {46},
year = {1990}
}
@article{Rosenblatt,
author = {Rosenblatt, F},
file = {::},
journal = {Psychological Review},
number = {6},
pages = {19--8},
title = {{THE PERCEPTRON: A PROBABILISTIC MODEL FOR INFORMATION STORAGE AND ORGANIZATION IN THE BRAIN}},
volume = {65}
}
@article{Lecun2006,
abstract = {To appear in " Predicting Structured Data " , G. Bakir, T. Hofman, B. Sch{\"{o}}lkopf, A. Smola, B. Taskar (eds) MIT Press, 2006 Abstract Energy-Based Models (EBMs) capture dependencies between variables by as-sociating a scalar energy to each configuration of the variables. Inference consists in clamping the value of observed variables and finding configurations of the re-maining variables that minimize the energy. Learning consists in finding an energy function in which observed configurations of the variables are given lower energies than unobserved ones. The EBM approach provides a common theoretical frame-work for many learning models, including traditional discriminative and genera-tive approaches, as well as graph-transformer networks, conditional random fields, maximum margin Markov networks, and several manifold learning methods. Probabilistic models must be properly normalized, which sometimes requires evaluating intractable integrals over the space of all possible variable configura-tions. Since EBMs have no requirement for proper normalization, this problem is naturally circumvented. EBMs can be viewed as a form of non-probabilistic factor graphs, and they provide considerably more flexibility in the design of architec-tures and training criteria than probabilistic approaches.},
author = {Lecun, Yann and Chopra, Sumit and Hadsell, Raia and Ranzato, Marc Aurelio and Huang, Fu Jie},
file = {::},
title = {{A Tutorial on Energy-Based Learning}},
url = {http://yann.lecun.com},
year = {2006}
}
@article{Glorot,
abstract = {While logistic sigmoid neurons are more bi-ologically plausible than hyperbolic tangent neurons, the latter work better for train-ing multi-layer neural networks. This pa-per shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hy-perbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros, which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier net-works can reach their best performance with-out requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at under-standing the difficulty in training deep but purely supervised neural networks, and clos-ing the performance gap between neural net-works learnt with and without unsupervised pre-training.},
author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
file = {::},
title = {{Deep Sparse Rectifier Neural Networks}}
}
@article{Bengio1997,
author = {Bengio, Y},
file = {::},
title = {{Convolutional Networks for Images, Speech, and Time-Series Parsing View project Oracle Performance for Visual Captioning View project}},
url = {https://www.researchgate.net/publication/2453996},
year = {1997}
}
@article{Svozil1997,
abstract = {Basic definitions concerning the multi-layer feed-forward neural networks are given. The back-propagation training algo-rithm is explained. Partial derivatives of the objective function with respect to the weight and threshold coefficients are de-rived. These derivatives are valuable for an adaptation process of the considered neural network. Training and generalisation of multi-layer feed-forward neural networks are discussed. Improvements of the standard back-propagation algorithm are re-viewed. Example of the use of multi-layer feed-forward neural networks for prediction of carbon-13 NMR chemical shifts of alkanes is given. Further applications of neural networks in chemistry are reviewed. Advantages and disadvantages of multi-layer feed-forward neural networks are discussed. 0 1997 Elsevier Science B.V.},
author = {Svozil, Daniel and Kvasnieka, Vladimir and Pospichal, Jie},
file = {::},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {Back-propagation network Contents,Neural networks},
pages = {43--62},
title = {{Chemometrics and intelligent laboratory systems Introduction to multi-layer feed-forward neural networks}},
volume = {39},
year = {1997}
}

@article{Elman,
abstract = {Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to rep-resent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit pat-terns are fed back to themselves: the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simula-tions is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands: indeed, in this approach the notion of memory is inextri-cably bound up with task processing. These representations reveal a rich struc-ture, which allows them to be highly context-dependent, while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction.},
author = {Elman, Jeffrey L},
doi = {10.1207/s15516709cog1402_1},
file = {::},
journal = {COGNITIVE SCIENCE},
number = {1},
pages = {179--21},
title = {{Finding Structure in Time}},
volume = {14}
}

@article{Chung2014,
abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
archivePrefix = {arXiv},
arxivId = {1412.3555},
author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
doi = {10.1109/IJCNN.2015.7280624},
eprint = {1412.3555},
file = {::},
isbn = {9781479919598},
issn = {2161-4393},
title = {{Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling}},
year = {2014}
}
@article{Socher,
abstract = {Natural language parsing has typically been done with small sets of discrete cate-gories such as NP and VP, but this representation does not capture the full syntactic nor semantic richness of linguistic phrases, and attempts to improve on this by lex-icalizing phrases only partly address the problem at the cost of huge feature spaces and sparseness. To address this, we introduce a recursive neural network architec-ture for jointly parsing natural language and learning vector space representations for variable-sized inputs. At the core of our architecture are context-sensitive re-cursive neural networks (CRNN). These networks can induce distributed feature representations for unseen phrases and provide syntactic information to accurately predict phrase structure trees. Most excitingly, the representation of each phrase also captures semantic information: For instance, the phrases " decline to com-ment " and " would not disclose the terms " are close by in the induced embedding space. Our current system achieves an unlabeled bracketing F-measure of 92.1{\%} on the Wall Street Journal dataset for sentences up to length 15.},
author = {Socher, Richard and Manning, Christopher D and Ng, Andrew Y},
file = {::},
title = {{Learning Continuous Phrase Representations and Syntactic Parsing with Recursive Neural Networks}}
}

@article{Rosenblatt,
author = {Rosenblatt, F},
file = {::},
journal = {Psychological Review},
number = {6},
pages = {19--8},
title = {{THE PERCEPTRON: A PROBABILISTIC MODEL FOR INFORMATION STORAGE AND ORGANIZATION IN THE BRAIN}},
volume = {65}
}

@article{Glorot,
abstract = {While logistic sigmoid neurons are more bi-ologically plausible than hyperbolic tangent neurons, the latter work better for train-ing multi-layer neural networks. This pa-per shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hy-perbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros, which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier net-works can reach their best performance with-out requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at under-standing the difficulty in training deep but purely supervised neural networks, and clos-ing the performance gap between neural net-works learnt with and without unsupervised pre-training.},
author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
file = {::},
title = {{Deep Sparse Rectifier Neural Networks}}
}

@article{Krizhevsky,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 dif-ferent classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%} which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make train-ing faster, we used non-saturating neurons and a very efficient GPU implemen-tation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called " dropout " that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
file = {::},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}}
}
@article{Hinton2012,
abstract = {When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This "overfitting" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random "dropout" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.},
archivePrefix = {arXiv},
arxivId = {1207.0580},
author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
doi = {arXiv:1207.0580},
eprint = {1207.0580},
file = {::},
isbn = {9781467394673},
issn = {9781467394673},
pmid = {1000104337},
title = {{Improving neural networks by preventing co-adaptation of feature detectors}},
year = {2012}
}

@article{Werbos1990,
abstract = {Basic backpropagation, which is a simple method now being widely$\backslash$nused in areas like pattern recognition and fault diagnosis, is reviewed.$\backslash$nThe basic equations for backpropagation through time, and applications$\backslash$nto areas like pattern recognition involving dynamic systems, systems$\backslash$nidentification, and control are discussed. Further extensions of this$\backslash$nmethod, to deal with systems other than neural networks, systems$\backslash$ninvolving simultaneous equations, or true recurrent networks, and other$\backslash$npractical issues arising with the method are described. Pseudocode is$\backslash$nprovided to clarify the algorithms. The chain rule for ordered$\backslash$nderivatives-the theorem which underlies backpropagation-is briefly$\backslash$ndiscussed. The focus is on designing a simpler version of$\backslash$nbackpropagation which can be translated into computer code and applied$\backslash$ndirectly by neutral network users},
author = {Werbos, Paul J.},
doi = {10.1109/5.58337},
file = {::},
isbn = {0018-9219},
issn = {15582256},
journal = {Proceedings of the IEEE},
title = {{Backpropagation Through Time: What It Does and How to Do It}},
year = {1990}
}
@article{Chung2014,
abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
archivePrefix = {arXiv},
arxivId = {1412.3555},
author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
doi = {10.1109/IJCNN.2015.7280624},
eprint = {1412.3555},
file = {::},
isbn = {9781479919598},
issn = {2161-4393},
title = {{Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling}},
year = {2014}
}

@article{Rosenblatt1958,
abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems.},
archivePrefix = {arXiv},
arxivId = {arXiv:1112.6209},
author = {Rosenblatt, F},
doi = {10.1037/h0042519},
eprint = {arXiv:1112.6209},
file = {::},
isbn = {0033-295X},
issn = {1939-1471(Electronic);0033-295X(Print)},
journal = {Psychological Review},
number = {6},
pages = {386--408},
pmid = {13602029},
title = {{The perceptron: A probabilistic model for information storage and organization in {\ldots}}},
url = {http://psycnet.apa.org/journals/rev/65/6/386.pdf{\%}5Cnpapers://c53d1644-cd41-40df-912d-ee195b4a4c2b/Paper/p15420},
volume = {65},
year = {1958}
}

@article{McCulloch1943,
abstract = {Because of the "all-or-none" character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {McCulloch, Warren S. and Pitts, Walter},
doi = {10.1007/BF02478259},
eprint = {arXiv:1011.1669v3},
file = {::},
isbn = {0007-4985},
issn = {00074985},
journal = {The Bulletin of Mathematical Biophysics},
pmid = {2185863},
title = {{A logical calculus of the ideas immanent in nervous activity}},
year = {1943}
}

